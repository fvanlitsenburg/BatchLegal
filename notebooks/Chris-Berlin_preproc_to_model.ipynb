{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b9035f",
   "metadata": {},
   "source": [
    "# Batch Legal Mockup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5e5bdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb2fb661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/christopher/code/fvanlitsenburg/BatchLegal/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0452bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading html-file + converting it into txt\n",
    "\n",
    "file = open(\"../raw_data/test_data.html\", \"r\")\n",
    "data = BeautifulSoup(file)\n",
    "as_txt = data.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7abf8765",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing the sentences\n",
    "\n",
    "as_sentences = sent_tokenize(as_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88d8f8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\nL_2022020EN.01000101.xml\\n\\n\\n\\n\\n\\n\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(2)\\n\\n\\nThe COVID-19 pandemic has highlighted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As recognised by the World Health Organization...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diseases may be transmitted from humans to ani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Approximately 70 % of emerging diseases, and a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>(19)  Regulation (EC) No 1049/2001 of the Euro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>(20)  Directive (EU) 2019/1937 of the European...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>(21)  Directive (EU) 2016/943 of the European ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>(22)  Regulation (EU, Euratom) 2018/1046 of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>(23)  Council Regulation (EC) No 297/95 of 10 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>565 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0\n",
       "0    \\n\\n\\nL_2022020EN.01000101.xml\\n\\n\\n\\n\\n\\n\\n\\n...\n",
       "1    (2)\\n\\n\\nThe COVID-19 pandemic has highlighted...\n",
       "2    As recognised by the World Health Organization...\n",
       "3    Diseases may be transmitted from humans to ani...\n",
       "4    Approximately 70 % of emerging diseases, and a...\n",
       "..                                                 ...\n",
       "560  (19)  Regulation (EC) No 1049/2001 of the Euro...\n",
       "561  (20)  Directive (EU) 2019/1937 of the European...\n",
       "562  (21)  Directive (EU) 2016/943 of the European ...\n",
       "563  (22)  Regulation (EU, Euratom) 2018/1046 of th...\n",
       "564  (23)  Council Regulation (EC) No 297/95 of 10 ...\n",
       "\n",
       "[565 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transforming sentences into DF\n",
    "\n",
    "txt_df = pd.DataFrame(as_sentences)\n",
    "txt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edc3cfb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(txt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4662a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_list = {'ec', 'no', 'european', 'commission', 'eu', 'union',\n",
    "                   'article', 'directive', 'council', 'regulation', 'official',\n",
    "                   'journal', 'article', 'information', 'agency', 'regulation',\n",
    "                   'mssg', 'data', 'member', 'states'\n",
    "                  } # list used to remove unrelevant terms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b80f77c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Davy's Preproc-Function\n",
    "\n",
    "def cleaning(sentence):\n",
    "    \n",
    "    # Basic cleaning\n",
    "    sentence = sentence.strip() ## remove whitespaces\n",
    "    sentence = sentence.lower() ## lowercasing \n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit()) ## removing numbers\n",
    "    \n",
    "    # Advanced cleaning\n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '') ## removing punctuation\n",
    "    tokenized_sentence = word_tokenize(sentence) ## tokenizing \n",
    "    stop_words = set(stopwords.words('english')) ## defining stopwords\n",
    "    tokenized_sentence_cleaned = [w for w in tokenized_sentence \n",
    "                                  if not w in stop_words] ## remove stopwords\n",
    "    tokenized_sentence_cleaned = [w for w in tokenized_sentence_cleaned\n",
    "                                  if not w in ignore_list]\n",
    "    lemmatized = [WordNetLemmatizer().lemmatize(word, pos = \"v\")  # v --> verbs\n",
    "              for word in tokenized_sentence_cleaned]\n",
    "    cleaned_sentence = ' '.join(word for word in lemmatized)\n",
    "    return cleaned_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecfe7b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Davy's Function\n",
    "\n",
    "clean_txt = txt_df[0].apply(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abc7b1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      lenxml en l parliament january reinforce role ...\n",
       "1      covid pandemic highlight interconnectedness hu...\n",
       "2      recognise world health organization many micro...\n",
       "3      diseases may transmit humans animals vice vers...\n",
       "4      approximately emerge diseases almost know pand...\n",
       "                             ...                        \n",
       "560    parliament may regard public access parliament...\n",
       "561    parliament october protection persons report b...\n",
       "562    parliament june protection undisclosed knowhow...\n",
       "563    euratom parliament july financial rule applica...\n",
       "564    february fee payable evaluation medicinal prod...\n",
       "Name: 0, Length: 565, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking outcome of Preprocessing\n",
    "clean_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99a7ace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorizing data\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorized_text = vectorizer.fit_transform(clean_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e31fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelling\n",
    "\n",
    "# Instantiating the LDA \n",
    "n_components = 3\n",
    "lda_model = LatentDirichletAllocation(n_components=n_components, max_iter = 100)\n",
    "\n",
    "# Fitting the LDA on the vectorized documents\n",
    "lda_model.fit(vectorized_text)\n",
    "\n",
    "# Getting topics\n",
    "topics = lda_model.transform(vectorized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f702cef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topic model function from ML-10-lecture\n",
    "def print_topics(model, vectorizer, top_words):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"-\"*20)\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names_out()[i], round(topic[i],2))\n",
    "                        for i in topic.argsort()[:-top_words - 1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc0aea23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Topic 0:\n",
      "[('health', 114.16), ('medicinal', 109.44), ('products', 108.94), ('public', 72.78), ('emergencies', 51.14), ('shortages', 48.6), ('medical', 44.35), ('parliament', 43.26)]\n",
      "--------------------\n",
      "Topic 1:\n",
      "[('medicinal', 148.16), ('refer', 133.16), ('shall', 121.71), ('products', 106.68), ('point', 95.23), ('list', 84.29), ('include', 77.33), ('critical', 75.78)]\n",
      "--------------------\n",
      "Topic 2:\n",
      "[('devices', 106.54), ('shall', 93.93), ('medical', 80.92), ('provide', 64.89), ('etf', 60.27), ('clinical', 56.22), ('mdssg', 52.56), ('representatives', 42.59)]\n"
     ]
    }
   ],
   "source": [
    "#Printing topics\n",
    "\n",
    "print_topics(lda_model, vectorizer, top_words = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85f0f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
